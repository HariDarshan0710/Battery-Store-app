{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0da1b0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\svhar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # For converting text data into numerical vectors\n",
    "from sklearn.model_selection import train_test_split  # For splitting dataset into training and testing sets\n",
    "from sklearn.linear_model import LogisticRegression  # For Logistic Regression classifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB  # For Naive Bayes classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier  # For K-Nearest Neighbors classifier\n",
    "from sklearn.svm import SVC  # For Support Vector Machine classifier\n",
    "from nltk.corpus import stopwords  # For stopwords\n",
    "from nltk.stem.porter import PorterStemmer  # For stemming words\n",
    "from sklearn.metrics import accuracy_score  # For calculating accuracy score\n",
    "import re  # For regular expressions\n",
    "import nltk  # Natural Language Toolkit\n",
    "\n",
    "# Downloading stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Read dataset\n",
    "dataset = pd.read_csv('Restaurant_Review.tsv', delimiter='\\t', quoting=3)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb802966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the dataset\n",
    "corpus = []\n",
    "for review in dataset['Review']:\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)  # Removing non-alphabetic characters\n",
    "    review = review.lower().split()  # Converting text to lowercase and splitting into words\n",
    "    ps = PorterStemmer()  # Creating a PorterStemmer object for word stemming\n",
    "    review = [ps.stem(word) for word in review if word not in set(stopwords.words('english'))]  # Stemming words and removing stopwords\n",
    "    review = ' '.join(review)  # Joining the words back into a sentence\n",
    "    corpus.append(review)  # Appending the preprocessed review to the corpus list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69d8a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Bag of Words model\n",
    "cv = CountVectorizer(max_features=1500)  # Initializing CountVectorizer with maximum 1500 features\n",
    "X = cv.fit_transform(corpus).toarray()  # Converting text corpus into numerical vectors\n",
    "y = dataset.iloc[:, 1].values  # Extracting the target variable (sentiment) from the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6186ec48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 71.00%\n",
      "SVC Accuracy: 73.50%\n",
      "GaussianNB Accuracy: 73.00%\n",
      "MultinomialNB Accuracy: 76.50%\n",
      "KNeighborsClassifier Accuracy: 58.50%\n"
     ]
    }
   ],
   "source": [
    "# Splitting dataset into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)  # Splitting data into 80% training and 20% testing sets\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),  # Initializing Logistic Regression classifier\n",
    "    \"SVC\": SVC(),  # Initializing Support Vector Machine classifier\n",
    "    \"GaussianNB\": GaussianNB(),  # Initializing Gaussian Naive Bayes classifier\n",
    "    \"MultinomialNB\": MultinomialNB(),  # Initializing Multinomial Naive Bayes classifier\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(n_neighbors=5)  # Initializing K-Nearest Neighbors classifier with k=5\n",
    "}\n",
    "\n",
    "# Train and evaluate classifiers\n",
    "for name, classifier in classifiers.items():\n",
    "    classifier.fit(X_train, y_train)  # Training the classifier\n",
    "    y_pred = classifier.predict(X_test)  # Predicting on the test set\n",
    "    accuracy = accuracy_score(y_test, y_pred)  # Calculating accuracy score\n",
    "    print(f\"{name} Accuracy: {accuracy * 100:.2f}%\")  # Printing accuracy for each classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7c147cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Predictions for Sample Review:\n",
      "Logistic Regression: Positive\n",
      "SVC: Positive\n",
      "GaussianNB: Positive\n",
      "MultinomialNB: Positive\n",
      "KNeighborsClassifier: Positive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to predict sentiment of a sample review\n",
    "def predict_sentiment(sample_review):\n",
    "    ps = PorterStemmer()  # Creating a PorterStemmer object for word stemming\n",
    "    sample_review = re.sub('[^a-zA-Z]', ' ', sample_review)  # Removing non-alphabetic characters\n",
    "    sample_review = sample_review.lower().split()  # Converting text to lowercase and splitting into words\n",
    "    sample_review = [ps.stem(word) for word in sample_review if word not in set(stopwords.words('english'))]  # Stemming words and removing stopwords\n",
    "    sample_review = ' '.join(sample_review)  # Joining the words back into a sentence\n",
    "    sample_vector = cv.transform([sample_review]).toarray()  # Converting sample review into numerical vector\n",
    "    predictions = {}  # Dictionary to store predictions\n",
    "    for name, classifier in classifiers.items():  # Looping through each classifier\n",
    "        predictions[name] = classifier.predict(sample_vector)[0]  # Making prediction using the classifier\n",
    "    return predictions  # Returning predictions\n",
    "\n",
    "# Sample review for prediction\n",
    "sample_review = \"The food was amazing and the service was great!\"\n",
    "\n",
    "# Predicting sentiment of sample review\n",
    "predictions = predict_sentiment(sample_review)  # Calling the predict_sentiment function\n",
    "print(\"Sentiment Predictions for Sample Review:\")\n",
    "for name, prediction in predictions.items():  # Looping through each prediction\n",
    "    print(f\"{name}: {'Positive' if prediction == 1 else 'Negative'}\")  # Printing sentiment prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801ad5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
